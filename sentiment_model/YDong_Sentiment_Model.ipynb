{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cQiztDIKphxH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\n",
        "    action=\"ignore\", category=FutureWarning\n",
        ")  # Deprecation warnings for later version of sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qLT2zwzLtIjx"
      },
      "outputs": [],
      "source": [
        "r_df = pd.read_csv(\"data/Reddit_Data.csv\")\n",
        "t_df = pd.read_csv(\"data/Twitter_Data.csv\")\n",
        "test_df = pd.read_csv(\"data/sentimentdataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S5xJ8r2eweoR"
      },
      "outputs": [],
      "source": [
        "r_df.columns = [\"Text\", \"Label\"]\n",
        "t_df.columns = [\"Text\", \"Label\"]\n",
        "\n",
        "r_df = r_df.dropna()\n",
        "t_df = t_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k_dye0Hxp7L",
        "outputId": "84177b2c-09dd-4235-f1b6-67f5ff20fe5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/michaelnguy/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"vader_lexicon\")\n",
        "\n",
        "\n",
        "def get_sentiment_label(word):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment_scores = sia.polarity_scores(word)\n",
        "    compound_score = sentiment_scores[\"compound\"]\n",
        "    if compound_score >= 0.05:\n",
        "        return 1  # Positive\n",
        "    elif compound_score <= -0.05:\n",
        "        return -1  # Negative\n",
        "    else:\n",
        "        return 0  # Neutral\n",
        "\n",
        "\n",
        "test_df[\"Label\"] = test_df[\"Sentiment\"].apply(get_sentiment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-S0Q4fTvt-9m"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([r_df, t_df])\n",
        "df[\"Text\"] = df[\"Text\"].astype(str)\n",
        "\n",
        "test_df[\"Text\"] = test_df[\"Text\"].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blbTA4u-hCG0"
      },
      "source": [
        "Text Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knpueR4k-Rgj",
        "outputId": "07ee5c21-08cd-4aae-b18c-d4f7a432a375"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/michaelnguy/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/michaelnguy/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/michaelnguy/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/michaelnguy/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import emoji\n",
        "import re\n",
        "import contractions\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Initialize the necessary tools\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Expand contractions\n",
        "    text = expand_contractions(text)\n",
        "\n",
        "    # Convert emojis to text\n",
        "    text = emoji.demojize(text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r\"@\\w+|#\\w+\", \" \", text)\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Lemmatize and stem each token\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token is not None]\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Remove duplicate tokens while preserving order\n",
        "    tokens = list(OrderedDict.fromkeys(tokens))\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = \" \".join(tokens)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Preprocess the comments\n",
        "df[\"Preproc\"] = df[\"Text\"].apply(preprocess_text)\n",
        "test_df[\"Preproc\"] = test_df[\"Text\"].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEwxEHxghKuS"
      },
      "source": [
        "Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Q5ohBmCv-p1z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df[\"Preproc\"], df[\"Label\"], test_size=0.2, random_state=42\n",
        ")\n",
        "X_test = test_df[\"Preproc\"]\n",
        "y_test = test_df[\"Label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWTmTcfP6HSq",
        "outputId": "a5cd078d-8ee5-433f-f4b7-57fb2277e907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with 0.75 1 (1, 1) 5000 0.1 lbfgs ovr\n",
            "done with 0.75 1 (1, 1) 5000 0.1 lbfgs multinomial\n",
            "done with 0.75 1 (1, 1) 5000 0.1 liblinear ovr\n",
            "done with 0.75 1 (1, 1) 5000 1 lbfgs ovr\n",
            "done with 0.75 1 (1, 1) 5000 1 lbfgs multinomial\n",
            "done with 0.75 1 (1, 1) 5000 1 liblinear ovr\n",
            "done with 0.75 1 (1, 1) 5000 10 lbfgs ovr\n",
            "done with 0.75 1 (1, 1) 5000 10 lbfgs multinomial\n",
            "done with 0.75 1 (1, 1) 5000 10 liblinear ovr\n",
            "done with 0.75 1 (1, 1) 5000 20 lbfgs ovr\n",
            "done with 0.75 1 (1, 1) 5000 20 lbfgs multinomial\n",
            "done with 0.75 1 (1, 1) 5000 20 liblinear ovr\n",
            "done with 0.75 1 (1, 1) 5000 50 lbfgs ovr\n",
            "done with 0.75 1 (1, 1) 5000 50 lbfgs multinomial\n",
            "done with 0.75 1 (1, 1) 5000 50 liblinear ovr\n",
            "done with 0.75 1 (1, 1) 5000 100 lbfgs ovr\n",
            "done with 0.75 1 (1, 1) 5000 100 lbfgs multinomial\n",
            "done with 0.75 1 (1, 1) 5000 100 liblinear ovr\n",
            "done with 0.75 1 (1, 2) 5000 0.1 lbfgs ovr\n",
            "done with 0.75 1 (1, 2) 5000 0.1 lbfgs multinomial\n",
            "done with 0.75 1 (1, 2) 5000 0.1 liblinear ovr\n",
            "done with 0.75 1 (1, 2) 5000 1 lbfgs ovr\n",
            "done with 0.75 1 (1, 2) 5000 1 lbfgs multinomial\n",
            "done with 0.75 1 (1, 2) 5000 1 liblinear ovr\n",
            "done with 0.75 1 (1, 2) 5000 10 lbfgs ovr\n",
            "done with 0.75 1 (1, 2) 5000 10 lbfgs multinomial\n",
            "done with 0.75 1 (1, 2) 5000 10 liblinear ovr\n",
            "done with 0.75 1 (1, 2) 5000 20 lbfgs ovr\n",
            "done with 0.75 1 (1, 2) 5000 20 lbfgs multinomial\n",
            "done with 0.75 1 (1, 2) 5000 20 liblinear ovr\n",
            "done with 0.75 1 (1, 2) 5000 50 lbfgs ovr\n",
            "done with 0.75 1 (1, 2) 5000 50 lbfgs multinomial\n",
            "done with 0.75 1 (1, 2) 5000 50 liblinear ovr\n",
            "done with 0.75 1 (1, 2) 5000 100 lbfgs ovr\n",
            "done with 0.75 1 (1, 2) 5000 100 lbfgs multinomial\n",
            "done with 0.75 1 (1, 2) 5000 100 liblinear ovr\n",
            "done with 0.75 2 (1, 1) 5000 0.1 lbfgs ovr\n",
            "done with 0.75 2 (1, 1) 5000 0.1 lbfgs multinomial\n",
            "done with 0.75 2 (1, 1) 5000 0.1 liblinear ovr\n",
            "done with 0.75 2 (1, 1) 5000 1 lbfgs ovr\n",
            "done with 0.75 2 (1, 1) 5000 1 lbfgs multinomial\n",
            "done with 0.75 2 (1, 1) 5000 1 liblinear ovr\n",
            "done with 0.75 2 (1, 1) 5000 10 lbfgs ovr\n",
            "done with 0.75 2 (1, 1) 5000 10 lbfgs multinomial\n",
            "done with 0.75 2 (1, 1) 5000 10 liblinear ovr\n",
            "done with 0.75 2 (1, 1) 5000 20 lbfgs ovr\n",
            "done with 0.75 2 (1, 1) 5000 20 lbfgs multinomial\n",
            "done with 0.75 2 (1, 1) 5000 20 liblinear ovr\n",
            "done with 0.75 2 (1, 1) 5000 50 lbfgs ovr\n",
            "done with 0.75 2 (1, 1) 5000 50 lbfgs multinomial\n",
            "done with 0.75 2 (1, 1) 5000 50 liblinear ovr\n",
            "done with 0.75 2 (1, 1) 5000 100 lbfgs ovr\n",
            "done with 0.75 2 (1, 1) 5000 100 lbfgs multinomial\n",
            "done with 0.75 2 (1, 1) 5000 100 liblinear ovr\n",
            "done with 0.75 2 (1, 2) 5000 0.1 lbfgs ovr\n",
            "done with 0.75 2 (1, 2) 5000 0.1 lbfgs multinomial\n",
            "done with 0.75 2 (1, 2) 5000 0.1 liblinear ovr\n",
            "done with 0.75 2 (1, 2) 5000 1 lbfgs ovr\n",
            "done with 0.75 2 (1, 2) 5000 1 lbfgs multinomial\n",
            "done with 0.75 2 (1, 2) 5000 1 liblinear ovr\n",
            "done with 0.75 2 (1, 2) 5000 10 lbfgs ovr\n",
            "done with 0.75 2 (1, 2) 5000 10 lbfgs multinomial\n",
            "done with 0.75 2 (1, 2) 5000 10 liblinear ovr\n",
            "done with 0.75 2 (1, 2) 5000 20 lbfgs ovr\n",
            "done with 0.75 2 (1, 2) 5000 20 lbfgs multinomial\n",
            "done with 0.75 2 (1, 2) 5000 20 liblinear ovr\n",
            "done with 0.75 2 (1, 2) 5000 50 lbfgs ovr\n",
            "done with 0.75 2 (1, 2) 5000 50 lbfgs multinomial\n",
            "done with 0.75 2 (1, 2) 5000 50 liblinear ovr\n",
            "done with 0.75 2 (1, 2) 5000 100 lbfgs ovr\n",
            "done with 0.75 2 (1, 2) 5000 100 lbfgs multinomial\n",
            "done with 0.75 2 (1, 2) 5000 100 liblinear ovr\n",
            "done with 1.0 1 (1, 1) 5000 0.1 lbfgs ovr\n",
            "done with 1.0 1 (1, 1) 5000 0.1 lbfgs multinomial\n",
            "done with 1.0 1 (1, 1) 5000 0.1 liblinear ovr\n",
            "done with 1.0 1 (1, 1) 5000 1 lbfgs ovr\n",
            "done with 1.0 1 (1, 1) 5000 1 lbfgs multinomial\n",
            "done with 1.0 1 (1, 1) 5000 1 liblinear ovr\n",
            "done with 1.0 1 (1, 1) 5000 10 lbfgs ovr\n",
            "done with 1.0 1 (1, 1) 5000 10 lbfgs multinomial\n",
            "done with 1.0 1 (1, 1) 5000 10 liblinear ovr\n",
            "done with 1.0 1 (1, 1) 5000 20 lbfgs ovr\n",
            "done with 1.0 1 (1, 1) 5000 20 lbfgs multinomial\n",
            "done with 1.0 1 (1, 1) 5000 20 liblinear ovr\n",
            "done with 1.0 1 (1, 1) 5000 50 lbfgs ovr\n",
            "done with 1.0 1 (1, 1) 5000 50 lbfgs multinomial\n",
            "done with 1.0 1 (1, 1) 5000 50 liblinear ovr\n",
            "done with 1.0 1 (1, 1) 5000 100 lbfgs ovr\n",
            "done with 1.0 1 (1, 1) 5000 100 lbfgs multinomial\n",
            "done with 1.0 1 (1, 1) 5000 100 liblinear ovr\n",
            "done with 1.0 1 (1, 2) 5000 0.1 lbfgs ovr\n",
            "done with 1.0 1 (1, 2) 5000 0.1 lbfgs multinomial\n",
            "done with 1.0 1 (1, 2) 5000 0.1 liblinear ovr\n",
            "done with 1.0 1 (1, 2) 5000 1 lbfgs ovr\n",
            "done with 1.0 1 (1, 2) 5000 1 lbfgs multinomial\n",
            "done with 1.0 1 (1, 2) 5000 1 liblinear ovr\n",
            "done with 1.0 1 (1, 2) 5000 10 lbfgs ovr\n",
            "done with 1.0 1 (1, 2) 5000 10 lbfgs multinomial\n",
            "done with 1.0 1 (1, 2) 5000 10 liblinear ovr\n",
            "done with 1.0 1 (1, 2) 5000 20 lbfgs ovr\n",
            "done with 1.0 1 (1, 2) 5000 20 lbfgs multinomial\n",
            "done with 1.0 1 (1, 2) 5000 20 liblinear ovr\n",
            "done with 1.0 1 (1, 2) 5000 50 lbfgs ovr\n",
            "done with 1.0 1 (1, 2) 5000 50 lbfgs multinomial\n",
            "done with 1.0 1 (1, 2) 5000 50 liblinear ovr\n",
            "done with 1.0 1 (1, 2) 5000 100 lbfgs ovr\n",
            "done with 1.0 1 (1, 2) 5000 100 lbfgs multinomial\n",
            "done with 1.0 1 (1, 2) 5000 100 liblinear ovr\n",
            "done with 1.0 2 (1, 1) 5000 0.1 lbfgs ovr\n",
            "done with 1.0 2 (1, 1) 5000 0.1 lbfgs multinomial\n",
            "done with 1.0 2 (1, 1) 5000 0.1 liblinear ovr\n",
            "done with 1.0 2 (1, 1) 5000 1 lbfgs ovr\n",
            "done with 1.0 2 (1, 1) 5000 1 lbfgs multinomial\n",
            "done with 1.0 2 (1, 1) 5000 1 liblinear ovr\n",
            "done with 1.0 2 (1, 1) 5000 10 lbfgs ovr\n",
            "done with 1.0 2 (1, 1) 5000 10 lbfgs multinomial\n",
            "done with 1.0 2 (1, 1) 5000 10 liblinear ovr\n",
            "done with 1.0 2 (1, 1) 5000 20 lbfgs ovr\n",
            "done with 1.0 2 (1, 1) 5000 20 lbfgs multinomial\n",
            "done with 1.0 2 (1, 1) 5000 20 liblinear ovr\n",
            "done with 1.0 2 (1, 1) 5000 50 lbfgs ovr\n",
            "done with 1.0 2 (1, 1) 5000 50 lbfgs multinomial\n",
            "done with 1.0 2 (1, 1) 5000 50 liblinear ovr\n",
            "done with 1.0 2 (1, 1) 5000 100 lbfgs ovr\n",
            "done with 1.0 2 (1, 1) 5000 100 lbfgs multinomial\n",
            "done with 1.0 2 (1, 1) 5000 100 liblinear ovr\n",
            "done with 1.0 2 (1, 2) 5000 0.1 lbfgs ovr\n",
            "done with 1.0 2 (1, 2) 5000 0.1 lbfgs multinomial\n",
            "done with 1.0 2 (1, 2) 5000 0.1 liblinear ovr\n",
            "done with 1.0 2 (1, 2) 5000 1 lbfgs ovr\n",
            "done with 1.0 2 (1, 2) 5000 1 lbfgs multinomial\n",
            "done with 1.0 2 (1, 2) 5000 1 liblinear ovr\n",
            "done with 1.0 2 (1, 2) 5000 10 lbfgs ovr\n",
            "done with 1.0 2 (1, 2) 5000 10 lbfgs multinomial\n",
            "done with 1.0 2 (1, 2) 5000 10 liblinear ovr\n",
            "done with 1.0 2 (1, 2) 5000 20 lbfgs ovr\n",
            "done with 1.0 2 (1, 2) 5000 20 lbfgs multinomial\n",
            "done with 1.0 2 (1, 2) 5000 20 liblinear ovr\n",
            "done with 1.0 2 (1, 2) 5000 50 lbfgs ovr\n",
            "done with 1.0 2 (1, 2) 5000 50 lbfgs multinomial\n",
            "done with 1.0 2 (1, 2) 5000 50 liblinear ovr\n",
            "done with 1.0 2 (1, 2) 5000 100 lbfgs ovr\n",
            "done with 1.0 2 (1, 2) 5000 100 lbfgs multinomial\n",
            "done with 1.0 2 (1, 2) 5000 100 liblinear ovr\n",
            "Best Vectorizer Parameters: {'max_df': 0.75, 'min_df': 2, 'ngram_range': (1, 1), 'max_features': 5000}\n",
            "Best Classifier Parameters: {'C': 20, 'solver': 'lbfgs', 'multi_class': 'ovr'}\n",
            "Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.67      0.36      0.47       183\n",
            "           0       0.27      0.49      0.35       171\n",
            "           1       0.70      0.60      0.65       378\n",
            "\n",
            "    accuracy                           0.52       732\n",
            "   macro avg       0.55      0.49      0.49       732\n",
            "weighted avg       0.59      0.52      0.53       732\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "# Define parameter grids for the vectorizer\n",
        "vectorizer_param_grid = {\n",
        "    \"max_df\": [0.75, 1.0],\n",
        "    \"min_df\": [1, 2],\n",
        "    \"ngram_range\": [(1, 1), (1, 2)],\n",
        "    \"max_features\": [5000],\n",
        "}\n",
        "\n",
        "# Define parameter grid for the classifier\n",
        "classifier_param_grid = {\n",
        "    \"C\": [0.1, 1, 10, 20, 50, 100],\n",
        "    \"solver\": [\"lbfgs\", \"liblinear\"],\n",
        "    \"multi_class\": [\"ovr\", \"multinomial\"],\n",
        "}\n",
        "\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "\n",
        "# Iterate over vectorizer parameter sets\n",
        "for max_df in vectorizer_param_grid[\"max_df\"]:\n",
        "    for min_df in vectorizer_param_grid[\"min_df\"]:\n",
        "        for ngram_range in vectorizer_param_grid[\"ngram_range\"]:\n",
        "            for max_features in vectorizer_param_grid[\"max_features\"]:\n",
        "                # Fit the vectorizer on the training set\n",
        "                vectorizer = TfidfVectorizer(\n",
        "                    max_df=max_df,\n",
        "                    min_df=min_df,\n",
        "                    ngram_range=ngram_range,\n",
        "                    max_features=max_features,\n",
        "                )\n",
        "                X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "                X_val_transformed = vectorizer.transform(X_val)\n",
        "\n",
        "                # Iterate over classifier parameter\n",
        "                for C in classifier_param_grid[\"C\"]:\n",
        "                    for solver in classifier_param_grid[\"solver\"]:\n",
        "                        for multi_class in classifier_param_grid[\"multi_class\"]:\n",
        "                            # Skip incompatible combinations\n",
        "                            if solver == \"liblinear\" and multi_class == \"multinomial\":\n",
        "                                continue\n",
        "                            # Train the classifier on the training set\n",
        "                            classifier = LogisticRegression(\n",
        "                                C=C,\n",
        "                                solver=solver,\n",
        "                                multi_class=multi_class,\n",
        "                                max_iter=10000,\n",
        "                            )\n",
        "                            try:\n",
        "                                classifier.fit(X_train_transformed, y_train)\n",
        "\n",
        "                                # Evaluate the classifier on the validation set\n",
        "                                y_val_pred = classifier.predict(X_val_transformed)\n",
        "                                score = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "                                # Check if this is the best model so far\n",
        "                                if score > best_score:\n",
        "                                    best_score = score\n",
        "                                    best_params = {\n",
        "                                        \"vectorizer\": {\n",
        "                                            \"max_df\": max_df,\n",
        "                                            \"min_df\": min_df,\n",
        "                                            \"ngram_range\": ngram_range,\n",
        "                                            \"max_features\": max_features,\n",
        "                                        },\n",
        "                                        \"classifier\": {\n",
        "                                            \"C\": C,\n",
        "                                            \"solver\": solver,\n",
        "                                            \"multi_class\": multi_class,\n",
        "                                        },\n",
        "                                    }\n",
        "                                print(\n",
        "                                    \"done with\",\n",
        "                                    max_df,\n",
        "                                    min_df,\n",
        "                                    ngram_range,\n",
        "                                    max_features,\n",
        "                                    C,\n",
        "                                    solver,\n",
        "                                    multi_class,\n",
        "                                )\n",
        "                            except Exception as e:\n",
        "                                print(f\"Skipping combination due to error: {e}\")\n",
        "\n",
        "# Fit the vectorizer and classifier on the combined training+validation set using the best parameters\n",
        "best_vectorizer_params = best_params[\"vectorizer\"]\n",
        "vectorizer = TfidfVectorizer(**best_vectorizer_params)\n",
        "X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "X_test_transformed = vectorizer.transform(X_test)\n",
        "\n",
        "best_classifier_params = best_params[\"classifier\"]\n",
        "classifier = LogisticRegression(**best_classifier_params, max_iter=10000)\n",
        "classifier.fit(X_train_transformed, y_train)\n",
        "\n",
        "# Evaluate the final model on the test set\n",
        "y_test_pred = classifier.predict(X_test_transformed)\n",
        "print(\"Best Vectorizer Parameters:\", best_vectorizer_params)\n",
        "print(\"Best Classifier Parameters:\", best_classifier_params)\n",
        "print(\"Test Set Performance:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd7RY46Gj7Zq"
      },
      "source": [
        "Initial testing on real-world data found out that this model performs poorly on emojis - because the train sets didn't have any emojis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bxpUOVrkVYc",
        "outputId": "75c63aa9-9984-4b52-e3f4-db680d2d2ba5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['Hello this is great',\n",
              "  'This stinks bad',\n",
              "  'before and before',\n",
              "  'I got the same water bottle',\n",
              "  'Yo more of these! Run through all the styles pls',\n",
              "  '🔥🔥🔥😍😍',\n",
              "  '😍😍😍',\n",
              "  '🔥',\n",
              "  \"Here's how to look exactly the same\",\n",
              "  'And that will be $150 sir',\n",
              "  '😍',\n",
              "  'Best model 👏🔥🔥',\n",
              "  'Where do you get a water bottle like that?',\n",
              "  'His eyes are the opposite of Moesha.',\n",
              "  'dumbbbbb handsome 😍',\n",
              "  'Wtf 👎🏼 trash 🗑️'],\n",
              " array([ 1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
              "         0.,  1., -1.])]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test on real-world data results:\n",
        "\n",
        "text = [\n",
        "    \"Hello this is great\",\n",
        "    \"This stinks bad\",\n",
        "    \"before and before\",\n",
        "    \"I got the same water bottle\",\n",
        "    \"Yo more of these! Run through all the styles pls\",\n",
        "    \"🔥🔥🔥😍😍\",\n",
        "    \"😍😍😍\",\n",
        "    \"🔥\",\n",
        "    \"Here's how to look exactly the same\",\n",
        "    \"And that will be $150 sir\",\n",
        "    \"😍\",\n",
        "    \"Best model 👏🔥🔥\",\n",
        "    \"Where do you get a water bottle like that?\",\n",
        "    \"His eyes are the opposite of Moesha.\",\n",
        "    \"dumbbbbb handsome 😍\",\n",
        "    \"Wtf 👎🏼 trash 🗑️\",\n",
        "]\n",
        "\n",
        "X_l = [preprocess_text(t) for t in text]\n",
        "X = pd.DataFrame(X_l)\n",
        "text_transformed = vectorizer.transform(X[0])\n",
        "senti_pred = classifier.predict(text_transformed)\n",
        "\n",
        "[text, senti_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cbCMZtGUCVN"
      },
      "source": [
        "I decided to add following entries into the training sets and run model again.\n",
        "\n",
        "https://www.kaggle.com/code/infamouscoder/emoji-sentiment-features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FcuQghk-QsQK"
      },
      "outputs": [],
      "source": [
        "positive_emoji = [\n",
        "    \"👏\",\n",
        "    \"🔥\",\n",
        "    \"😍\",\n",
        "    \"😊\",\n",
        "    \"💕\",\n",
        "    \"👍\",\n",
        "    \"💖\",\n",
        "    \"😊\",\n",
        "    \"🎉\",\n",
        "    \"💞\",\n",
        "    \"😃\",\n",
        "    \"😁\",\n",
        "    \"😎\",\n",
        "    \"😘\",\n",
        "    \"💓\",\n",
        "    \"😉\",\n",
        "    \"😄\",\n",
        "    \"😀\",\n",
        "    \"💗\",\n",
        "    \"😌\",\n",
        "    \"😆\",\n",
        "    \"😻\",\n",
        "    \"🙋\",\n",
        "    \"😇\",\n",
        "    \"💝\",\n",
        "    \"😋\",\n",
        "    \"🤗\",\n",
        "    \"😚\",\n",
        "    \"😙\",\n",
        "    \"😸\",\n",
        "    \"😺\",\n",
        "    \"😽\",\n",
        "]\n",
        "\n",
        "negative_emoji = [\n",
        "    \"🗑️\",\n",
        "    \"👎\",\n",
        "    \"😫\",\n",
        "    \"😨\",\n",
        "    \"😢\",\n",
        "    \"💀\",\n",
        "    \"🤔\",\n",
        "    \"😓\",\n",
        "    \"😤\",\n",
        "    \"😩\",\n",
        "    \"😴\",\n",
        "    \"💔\",\n",
        "    \"😒\",\n",
        "    \"😪\",\n",
        "    \"😣\",\n",
        "    \"😡\",\n",
        "    \"😕\",\n",
        "    \"😔\",\n",
        "    \"😠\",\n",
        "    \"😷\",\n",
        "    \"😥\",\n",
        "    \"😞\",\n",
        "    \"😲\",\n",
        "    \"😰\",\n",
        "    \"😖\",\n",
        "    \"😧\",\n",
        "    \"😟\",\n",
        "    \"😶\",\n",
        "    \"😯\",\n",
        "    \"🤒\",\n",
        "    \"🤕\",\n",
        "    \"😾\",\n",
        "    \"💤\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HNoT_ZhigXGZ"
      },
      "outputs": [],
      "source": [
        "preproc_pe = [preprocess_text(e) for e in positive_emoji]\n",
        "\n",
        "X_train = pd.concat([X_train, pd.DataFrame(preproc_pe)], ignore_index=True, axis=0)\n",
        "y_train = pd.concat([y_train, pd.DataFrame([1] * 32)], ignore_index=True, axis=0)\n",
        "\n",
        "preproc_ne = [preprocess_text(e) for e in negative_emoji]\n",
        "\n",
        "X_train = pd.concat([X_train, pd.DataFrame(preproc_ne)], ignore_index=True, axis=0)\n",
        "y_train = pd.concat([y_train, pd.DataFrame([-1] * 33)], ignore_index=True, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jFez9SsrNwc",
        "outputId": "10a9d980-406f-4d3b-b571-6ecfc688f436"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/michaelnguy/miniforge3/envs/playgroundenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  # only csr, csc, and coo have `data` attribute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['Hello this is great',\n",
              "  'This stinks bad',\n",
              "  'before and before',\n",
              "  'I got the same water bottle',\n",
              "  'Yo more of these! Run through all the styles pls',\n",
              "  '🔥🔥🔥😍😍',\n",
              "  '😍😍😍',\n",
              "  '🔥',\n",
              "  \"Here's how to look exactly the same\",\n",
              "  'And that will be $150 sir',\n",
              "  '😍',\n",
              "  'Best model 👏🔥🔥',\n",
              "  'Where do you get a water bottle like that?',\n",
              "  'His eyes are the opposite of Moesha.',\n",
              "  'dumbbbbb handsome 😍',\n",
              "  'Wtf 👎🏼 trash 🗑️'],\n",
              " array([ 1., -1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
              "         0.,  1., -1.])]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# X_train = X_train.astype(str)\n",
        "X_train_transformed = vectorizer.fit_transform(X_train[0])\n",
        "\n",
        "classifier.fit(X_train_transformed, y_train)\n",
        "\n",
        "# Re-test on real-world data\n",
        "X_l = [preprocess_text(t) for t in text]\n",
        "X = pd.DataFrame(X_l)\n",
        "text_transformed = vectorizer.transform(X[0])\n",
        "senti_pred = classifier.predict(text_transformed)\n",
        "\n",
        "[text, senti_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_NZBkMDfJMp"
      },
      "source": [
        "Hyperparameter Sensitivity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "NRIx3GOKfH1x",
        "outputId": "7170aa04-82c6-4004-eb8b-a3aecc261c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Param: C, Value: 0.1, Mean Accuracy Score: 0.5164, Std: 0.0026\n",
            "Param: C, Value: 1, Mean Accuracy Score: 0.6051, Std: 0.0617\n",
            "Param: C, Value: 10, Mean Accuracy Score: 0.6624, Std: 0.0697\n",
            "Param: C, Value: 20, Mean Accuracy Score: 0.6487, Std: 0.0721\n",
            "Param: C, Value: 50, Mean Accuracy Score: 0.6460, Std: 0.0707\n",
            "Param: C, Value: 100, Mean Accuracy Score: 0.6460, Std: 0.0677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lp/k6q1n4l164l7s056_kj52d3c0000gn/T/ipykernel_63635/3545529432.py:49: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  plt.legend()\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_test_trans = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "def sensitivity_analysis(model, param_grid, X, y, scorer, cv=5):\n",
        "    results = []\n",
        "    for param, values in param_grid.items():\n",
        "        for value in values:\n",
        "            model.set_params(**{param: value})\n",
        "            scores = cross_val_score(model, X, y, cv=cv, scoring=scorer, n_jobs=None)\n",
        "            mean_score = np.mean(scores)\n",
        "            std_score = np.std(scores)\n",
        "            results.append((param, value, mean_score, std_score))\n",
        "            print(\n",
        "                f\"Param: {param}, Value: {value}, Mean Accuracy Score: {mean_score:.4f}, Std: {std_score:.4f}\"\n",
        "            )\n",
        "    return results\n",
        "\n",
        "\n",
        "param_grid = {\"C\": [0.1, 1, 10, 20, 50, 100]}\n",
        "\n",
        "\n",
        "def accuracy(estimator, X, y):\n",
        "    y_pred = estimator.predict(X)\n",
        "    return accuracy_score(y, y_pred)\n",
        "\n",
        "\n",
        "sensitivity_results = sensitivity_analysis(\n",
        "    classifier, param_grid, X_test_trans, y_test, accuracy, cv=5\n",
        ")\n",
        "\n",
        "sensitivity_df = pd.DataFrame(\n",
        "    sensitivity_results, columns=[\"Parameter\", \"Value\", \"Mean Accuracy Score\", \"Std\"]\n",
        ")\n",
        "\n",
        "\n",
        "for param in param_grid.keys():\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    subset = sensitivity_df[sensitivity_df[\"Parameter\"] == param]\n",
        "    plt.errorbar(\n",
        "        subset[\"Value\"], subset[\"Mean Accuracy Score\"], yerr=subset[\"Std\"], fmt=\"-o\"\n",
        "    )  # label=param\n",
        "\n",
        "    plt.xlabel(param)\n",
        "    plt.ylabel(\"Mean Accuracy Score\")\n",
        "    plt.title(\"Hyperparameter Sensitivity Analysis\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
